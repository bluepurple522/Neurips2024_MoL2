{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet50, densenet121, mobilenet_v2\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model train\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()  \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device) \n",
    "        optimizer.zero_grad() \n",
    "        output = model(data)  \n",
    "        loss = F.cross_entropy(output, target) \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "# For model evaluation\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()  \n",
    "    test_loss = 0 \n",
    "    correct = 0   \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:  \n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            output = model(data) \n",
    "            \n",
    "            test_loss += F.cross_entropy(output,target, reduction='sum').item() \n",
    " \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() \n",
    "            \n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "   \n",
    "    test_loss /= len(test_loader.dataset) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) \n",
    "    \n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    \n",
    "    # Obtaining probability values for AUC calculation\n",
    "    fpr, tpr, _ = roc_curve(all_targets, all_predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return test_loss, test_accuracy, cm, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file directory containing the mtf translation image\n",
    "data_dir = '../MTF_spl/'\n",
    "\n",
    "# Set desired hyperparameters\n",
    "learning_rate = 2*(1e-3)\n",
    "epoch = 100\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can divide the dataset ratio before training the model. \n",
    "# If you want, set it to train and validation dataset\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([transforms.Resize([224,224]), \n",
    "        transforms.RandomHorizontalFlip(), transforms.RandomVerticalFlip(),  \n",
    "        transforms.RandomCrop(52), transforms.ToTensor(), \n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ]),\n",
    "}\n",
    "\n",
    "# Read input image data through dataloader\n",
    "image_datasets = {'train': ImageFolder(root=os.path.join(data_dir, 'train'), transform=data_transforms['train'])}\n",
    "dataloaders = {'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, shuffle=True, num_workers=4)}\n",
    "dataset_sizes = {'train': len(image_datasets['train'])}\n",
    "\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is written on the assumption that there is only a train set based on transfer learning\n",
    "def train_transfer(model, criterion, optimizer, num_epochs):\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())  \n",
    "    best_acc = 0.0  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('-------------- epoch {} ----------------'.format(epoch+1)) \n",
    "        since = time.time()                                     \n",
    "        phase = 'train' \n",
    "        model.train()  \n",
    " \n",
    "        running_loss = 0.0  \n",
    "        running_corrects = 0  \n",
    " \n",
    "        for inputs, labels in dataloaders[phase]: \n",
    "            inputs = inputs.to(device)  \n",
    "            labels = labels.to(device)   \n",
    "                \n",
    "            optimizer.zero_grad() \n",
    "                \n",
    "            with torch.set_grad_enabled(True):  \n",
    "                outputs = model(inputs)  \n",
    "                _, preds = torch.max(outputs, 1) \n",
    "                loss = criterion(outputs, labels)  \n",
    "    \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    " \n",
    "            running_loss += loss.item() * inputs.size(0)  \n",
    "            running_corrects += torch.sum(preds == labels.data)  \n",
    "                \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]  \n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]  \n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "        if epoch_acc > best_acc: \n",
    "            best_acc = epoch_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    " \n",
    "        time_elapsed = time.time() - since  \n",
    "        print('Completed in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        \n",
    "    print('Best train Acc: {:4f}'.format(best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts) \n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the desired model and set the output of the last layer to 2\n",
    "model = resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048,2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(model.parameters(), lr=2*(1e-3), weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the model training as much as you want, save the model\n",
    "ResNet50_epoch_100 = train_transfer(model, criterion, optimizer, num_epochs=100)\n",
    "torch.save(ResNet50_epoch_100, 'ResNet50_epoch_100.pt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model can be changed however you want.\n",
    "### The structure of MoL2 is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = mobilenet_v2(pretrained=True)\n",
    "\n",
    "feature_extractor = torch.nn.Sequential(*list(mobilenet.children())[:-1])\n",
    "\n",
    "class MoL2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MoL2, self).__init__()\n",
    "        self.features = feature_extractor\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, 2)  \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "innie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
