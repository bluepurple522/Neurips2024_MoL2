{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import copy\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision.models import resnet50, densenet121, mobilenet_v2\n",
    "from torchvision.datasets import ImageFolder \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, auc, f1_score\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When testing the model, you must set it to include only the original image\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize([224,224]),  \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "    ])\n",
    "\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the file directory containing the mtf translation image\n",
    "test_transfer = ImageFolder(root='../MTF_spl/test', transform=transform) \n",
    "test_loader = torch.utils.data.DataLoader(test_transfer, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "class_names = test_transfer.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the model test 100 times to represent the median value of each result.\n",
    "def evaluate(model, test_loader, num_evaluations=100):\n",
    "    model.eval()  \n",
    "    \n",
    "    # List to store each evaluation result\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    confusion_matrices = []\n",
    "    roc_aucs = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for _ in range(num_evaluations):\n",
    "        test_loss, test_accuracy, cm, roc_auc, f1 = single_evaluation(model, test_loader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        confusion_matrices.append(cm)\n",
    "        roc_aucs.append(roc_auc)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    # Calculate the median values\n",
    "    median_test_loss = np.median(test_losses)\n",
    "    median_test_accuracy = np.median(test_accuracies)\n",
    "    median_confusion_matrix = np.median(confusion_matrices, axis=0)\n",
    "    median_roc_auc = np.median(roc_aucs)\n",
    "    median_f1_score = np.median(f1_scores)\n",
    "\n",
    "    return median_test_loss, median_test_accuracy, median_confusion_matrix, median_roc_auc, median_f1_score\n",
    "\n",
    "def single_evaluation(model, test_loader):\n",
    "    test_loss = 0 \n",
    "    correct = 0   \n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data, target in test_loader:  \n",
    "            data, target = data.to(device), target.to(device)  \n",
    "            output = model(data) \n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() \n",
    "            \n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item() \n",
    "            \n",
    "            all_predictions.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "   \n",
    "    test_loss /= len(test_loader.dataset) \n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset) \n",
    "    \n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    \n",
    "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(all_targets, all_predictions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    return test_loss, test_accuracy, cm, roc_auc, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet50_epoch_100=torch.load('ResNet50_epoch_100.pt') \n",
    "ResNet50_epoch_100.eval()  \n",
    "test_loss, test_accuracy, cm, roc_auc, f1  = evaluate(ResNet50_epoch_100, test_loader)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)\n",
    "\n",
    "print('ResNet50_epoch_100 test acc:  ', test_accuracy)\n",
    "print('ResNet50_epoch_100 test loss: ', test_loss)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"Specificity: {specificity}\")\n",
    "print(f\"Sensitivity: {sensitivity}\")\n",
    "print(f\"AUC: {roc_auc}\")\n",
    "print(f\"f1 score : {f1}\")\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"0.1f\", cmap=\"Blues\", \n",
    "            xticklabels=class_names, yticklabels=class_names, \n",
    "            annot_kws={\"size\":15})\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('ResNet50_epoch_100 Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
